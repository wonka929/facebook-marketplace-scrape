{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1952ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " //  Digitare \"q\" nella chiave di ricerca per uscire dal processo di scraping. // \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci la chiave di ricerca:  imac\n",
      "Inserisci la città:  parma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho trovato questa città: procedo con essa... \n",
      "\t- Parma\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci il numero di pagine da analizzare:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:15<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci la chiave di ricerca:  bicicletta\n",
      "Inserisci la città:  bologna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho trovato questa città: procedo con essa... \n",
      "\t- Bologna\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci il numero di pagine da analizzare:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:09<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci la chiave di ricerca:  sedia\n",
      "Inserisci la città:  brescia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho trovato questa città: procedo con essa... \n",
      "\t- Brescia\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci il numero di pagine da analizzare:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:06<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Inserisci la chiave di ricerca:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      60\n",
      "1      70\n",
      "2      10\n",
      "3       1\n",
      "4      20\n",
      "5     100\n",
      "6      10\n",
      "7      15\n",
      "8      45\n",
      "9      25\n",
      "10     20\n",
      "11     15\n",
      "12     30\n",
      "13     45\n",
      "14      1\n",
      "15     20\n",
      "16      1\n",
      "17     30\n",
      "18     45\n",
      "19      1\n",
      "20     20\n",
      "21      5\n",
      "22     30\n",
      "23     60\n",
      "24     30\n",
      "25     15\n",
      "26     60\n",
      "27     20\n",
      "28     60\n",
      "29     25\n",
      "30    250\n",
      "31     40\n",
      "32     70\n",
      "33     50\n",
      "34     15\n",
      "35     65\n",
      "36      7\n",
      "37     15\n",
      "38     80\n",
      "39     25\n",
      "40     40\n",
      "41     60\n",
      "42     20\n",
      "43     10\n",
      "44     10\n",
      "Name: prezzo, dtype: object\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m descrizione \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma8c37x1j ni8dbmo4 stjgntxs l9j0dhe7\u001b[39m\u001b[38;5;124m\"\u001b[39m})[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    118\u001b[0m location \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma8c37x1j ni8dbmo4 stjgntxs l9j0dhe7 ltmttdrg g0qnabr5\u001b[39m\u001b[38;5;124m\"\u001b[39m})[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m--> 119\u001b[0m prezzo \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprezzo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<img src=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m elem\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    121\u001b[0m dic \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescrizione\u001b[39m\u001b[38;5;124m'\u001b[39m : descrizione,\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprezzo\u001b[39m\u001b[38;5;124m'\u001b[39m : prezzo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimmagine\u001b[39m\u001b[38;5;124m'\u001b[39m : image\n\u001b[1;32m    127\u001b[0m }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from tqdm import trange, tqdm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "\n",
    "with open('cities.pickle', 'rb') as f:\n",
    "    cities = pickle.load(f)\n",
    "\n",
    "    \n",
    "def scrape(n_pag=5):\n",
    "    for i in trange(n_pag):\n",
    "        sleep(3)\n",
    "        driver.find_element(by='tag name', value='html').send_keys(Keys.END)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    return soup\n",
    "\n",
    "\n",
    "## Browser setup\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "#options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--log-level=3\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('--window-size=1376,768')\n",
    "\n",
    "# Pass the argument 1 to allow and 2 to block\n",
    "options.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 1 \n",
    "})\n",
    "#options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    " ## Facebook Login\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#driver.get('https://it-it.facebook.com/login/?next=%2Fmarketplace%2F')\n",
    "\n",
    "driver.get('https://it-it.facebook.com/marketplace/turin/search/?query=')\n",
    "\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='Consenti solo i cookie essenziali']\"))).click()\n",
    "\n",
    "#driver.find_element(by='xpath', value=\"/html/body/div[3]/div[2]/div/div/div/div/div[3]/button[1]\").click()\n",
    "#driver.find_element(by='id', value=\"email\").send_keys(\"xxx\")\n",
    "#driver.find_element(by='id', value=\"pass\").send_keys(\"xxx\")\n",
    "#driver.find_element(by='id', value=\"loginbutton\").click()\n",
    "#sleep(8)\n",
    "\n",
    "print('\\n //  Digitare \"q\" nella chiave di ricerca per uscire dal processo di scraping. // \\n')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    chiave_ricerca = input(\"Inserisci la chiave di ricerca: \")\n",
    "    if chiave_ricerca == 'q':\n",
    "        break\n",
    "    chiave_ricerca = chiave_ricerca.replace(' ',' ')\n",
    "    \n",
    "    citta = input(\"Inserisci la città: \")\n",
    "    identified = process.extractOne(citta, cities.keys())\n",
    "    print(\"Ho trovato questa città: procedo con essa...\", \"\\n\\t-\", identified[0]), \n",
    "    \n",
    "    id = str(cities[identified[0]])\n",
    "    \n",
    "    pagine = input(\"Inserisci il numero di pagine da analizzare: \")\n",
    "    pagine = int(pagine)\n",
    "    \n",
    "    driver.get('https://it-it.facebook.com/marketplace/' + id + '/search/?query=' + chiave_ricerca)\n",
    "    \n",
    "    sleep(3)\n",
    "  \n",
    "    #driver.find_element(by='xpath', value=\"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div[1]/div/div[3]/div[1]/div[2]/div[3]/div[2]/div[1]/div[1]/div/span\").click()\n",
    "    #sleep(1)\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]/div/div[2]/div/div/div/div/div/label/div/div[2]/input').send_keys(Keys.CONTROL + \"a\")\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]/div/div[2]/div/div/div/div/div/label/div/div[2]/input').send_keys(Keys.DELETE)\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]/div/div[2]/div/div/div/div/div/label/div/div[2]/input').send_keys(citta)\n",
    "    #sleep(2)\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]/div/div[2]/div/div/div/div/div/label/div/div[2]/input').send_keys(Keys.DOWN)\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]/div/div[2]/div/div/div/div/div/label/div/div[2]/input').send_keys(Keys.ENTER)\n",
    "    #driver.find_element(by='xpath', value='/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[4]/div/div[2]/div/div').click()\n",
    "    #sleep(5)\n",
    "    \n",
    "    soup = scrape(pagine)\n",
    "    \n",
    "    with open( citta + '_' + chiave_ricerca.replace(' ','_') + \".html\", \"w\", encoding='utf-8') as file:\n",
    "        file.write(str(soup))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.html'):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            contents = f.read()\n",
    "            soup = BeautifulSoup(contents, 'lxml')\n",
    "        \n",
    "        output = pd.DataFrame()\n",
    "        a = soup.findAll(\"div\", {\"class\" : \"kbiprv82\"})\n",
    "        for elem in a:\n",
    "            link = '<a href=https://it-it.facebook.com' + elem.findAll(\"a\", {\"class\" : \"oajrlxb2 g5ia77u1 qu0x051f esr5mh6w e9989ue4 r7d6kgcz rq0escxv nhd2j8a9 nc684nl6 p7hjln8o kvgmc6g5 cxmmr5t8 oygrvhab hcukyx3x jb3vyjys rz4wbd8a qt6c0cv9 a8nywdso i1ao9s8h esuyzwwr f1sip0of lzcic4wl gmql0nx0 p8dawk7l\"})[0]['href'] + '>' + 'Link annuncio' + '</a>'\n",
    "            prezzo = elem.findAll(\"span\", {\"class\" : \"d2edcug0 hpfvmrgz qv66sw1b c1et5uql b0tq1wua a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 tia6h79c iv3no6db a5q79mjw g1cxx5fr lrazzd5p oo9gr5id\"})[0].text\n",
    "            descrizione = elem.findAll(\"span\", {\"class\" : \"a8c37x1j ni8dbmo4 stjgntxs l9j0dhe7\"})[0].text\n",
    "            location = elem.findAll(\"span\", {\"class\" : \"a8c37x1j ni8dbmo4 stjgntxs l9j0dhe7 ltmttdrg g0qnabr5\"})[0].text\n",
    "            prezzo = re.findall(r'\\b\\d+\\b', prezzo)[0]\n",
    "            image = '<img src=\"'+ elem.find('img')['src'] + '\">'\n",
    "            dic = {\n",
    "                'descrizione' : descrizione,\n",
    "                'prezzo' : prezzo,\n",
    "                'location' : location,\n",
    "                'link' : link,\n",
    "                'immagine' : image\n",
    "            }\n",
    "\n",
    "            output = output.append(dic, ignore_index=True)\n",
    "        \n",
    "        output['prezzo'] = pd.to_numeric(output['prezzo'], errors='coerce')\n",
    "        output = output.sort_values(by='prezzo').reset_index(drop=True)\n",
    "        output.to_csv(file.split('.')[0] + '.csv', sep=';')\n",
    "        output.to_html(file.split('.')[0] + '_web.html', escape=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
